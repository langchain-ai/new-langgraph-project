{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04e7215d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Optional, Literal,Annotated, TypedDict\n",
    "from pydantic import BaseModel\n",
    "from langchain_core.messages import AIMessage, HumanMessage, SystemMessage, AnyMessage\n",
    "from langgraph.graph.message import add_messages\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langchain.chat_models import init_chat_model\n",
    "from langgraph.types import interrupt, Command\n",
    "\n",
    "llm = init_chat_model(model=\"openai:gpt-4o\")\n",
    "\n",
    "QUESTIONS = [\n",
    "    \"What is the name of the competitor?\",\n",
    "    \"Whats your favorite color?\",\n",
    "    \"Pick a number between 1 and 100\",\n",
    "    \"What is your name?\"\n",
    "]\n",
    "\n",
    "class CompetitiveAnalysisState(TypedDict):\n",
    "    messages: Annotated[list[AnyMessage], add_messages]\n",
    "    user_answered_all_questions: bool\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eaff542",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = \"\"\"\n",
    "You need to verify the user answered all the questions and if not, ask the next question.\n",
    "The list of questions is:\n",
    "{QUESTIONS}\n",
    "\n",
    "User the history of messages to verify if the user answered all the questions.\n",
    "\"\"\"\n",
    "\n",
    "class next_question(BaseModel):\n",
    "    question: str\n",
    "    answered_all_questions: bool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "717a0378",
   "metadata": {},
   "outputs": [],
   "source": [
    "def CompetitiveAnalysisNode(state: CompetitiveAnalysisState):\n",
    "    system_message = SystemMessage(content=system_prompt)\n",
    "    history = state['messages']\n",
    "    messages = [system_message] + history\n",
    "    llm_with_structured_output = llm.with_structured_output(next_question)\n",
    "    ai_message = llm_with_structured_output.invoke(messages)\n",
    "\n",
    "    user_response = interrupt({\n",
    "        \"question\": ai_message,\n",
    "    })\n",
    "    messages.append(AIMessage(content=ai_message))\n",
    "    messages.append(HumanMessage(content=user_response))\n",
    "\n",
    "    return {\"messages\": messages}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "builder = StateGraph(CompetitiveAnalysisState)\n",
    "\n",
    "builder.add_node(\"CompetitiveAnalysisNode\", CompetitiveAnalysisNode)\n",
    "builder.add_edge(START, \"CompetitiveAnalysisNode\")\n",
    "builder.add_edge(\"CompetitiveAnalysisNode\", END)\n",
    "\n",
    "graph = builder.compile()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
